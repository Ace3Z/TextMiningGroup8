{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab4-Assignment about Named Entity Recognition and Classification\n",
    "\n",
    "This notebook describes the assignment of Lab 4 of the text mining course. We assume you have succesfully completed Lab1, Lab2 and Lab3 as welll. Especially Lab2 is important for completing this assignment.\n",
    "\n",
    "**Learning goals**\n",
    "* going from linguistic input format to representing it in a feature space\n",
    "* working with pretrained word embeddings\n",
    "* train a supervised classifier (SVM)\n",
    "* evaluate a supervised classifier (SVM)\n",
    "* learn how to interpret the system output and the evaluation results\n",
    "* be able to propose future improvements based on the observed results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "This notebook was originally created by [Marten Postma](https://martenpostma.github.io) and [Filip Ilievski](http://ilievski.nl) and adapted by Piek vossen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Added by Mahbod, for imports\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Points: 18] Exercise 1 (NERC): Training and evaluating an SVM using CoNLL-2003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4 point] a) Load the CoNLL-2003 training data using the *ConllCorpusReader* and create for both *train.txt* and *test.txt*:**\n",
    "\n",
    "    [2 points]  -a list of dictionaries representing the features for each training instances, e..g,\n",
    "    ```\n",
    "    [\n",
    "    {'words': 'EU', 'pos': 'NNP'}, \n",
    "    {'words': 'rejects', 'pos': 'VBZ'},\n",
    "    ...\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "    [2 points] -the NERC labels associated with each training instance, e.g.,\n",
    "    dictionaries, e.g.,\n",
    "    ```\n",
    "    [\n",
    "    'B-ORG', \n",
    "    'O',\n",
    "    ....\n",
    "    ]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Training Features: [{'words': 'EU', 'pos': 'NNP'}, {'words': 'rejects', 'pos': 'VBZ'}]\n",
      "Sample Training Labels: ['B-ORG', 'O']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "### Adapt the path to point to the CONLL2003 folder on your local machine\n",
    "train = ConllCorpusReader(\"./CONLL2003\", 'train.txt', ['words', 'pos', 'ignore', 'chunk']) # if you pull from the repo, path shall be fine\n",
    "\n",
    "training_features = []\n",
    "training_gold_labels = []\n",
    "\n",
    "for token, pos, ne_label in train.iob_words():\n",
    "   # create the features dictionary for the instance\n",
    "   features_dict = {\n",
    "      'words': token, 'pos': pos\n",
    "   }\n",
    "   # append the features and NE label of the instance\n",
    "   training_features.append(features_dict)\n",
    "   training_gold_labels.append(ne_label)\n",
    "   \n",
    "# check\n",
    "print(\"Sample Training Features:\", training_features[:2])\n",
    "print(\"Sample Training Labels:\", training_gold_labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Test Features: [{'words': 'SOCCER', 'pos': 'NN'}, {'words': '-', 'pos': ':'}]\n",
      "Sample Test Labels: ['O', 'O']\n"
     ]
    }
   ],
   "source": [
    "### Adapt the path to point to the CONLL2003 folder on your local machine\n",
    "test = ConllCorpusReader(\"./CONLL2003\", 'test.txt', ['words', 'pos', 'ignore', 'chunk'])\n",
    "\n",
    "test_features = []\n",
    "test_gold_labels = []\n",
    "for token, pos, ne_label in test.iob_words():\n",
    "    # create the features dictionary for the instance\n",
    "    features_dict = {\n",
    "        'words': token, 'pos': pos\n",
    "    }\n",
    "    # append the features and NE label of the instance\n",
    "    test_features.append(features_dict)\n",
    "    test_gold_labels.append(ne_label)\n",
    "\n",
    "# check\n",
    "print(\"Sample Test Features:\", test_features[:2])\n",
    "print(\"Sample Test Labels:\", test_gold_labels[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2 points] b) provide descriptive statistics about the training and test data:**\n",
    "* How many instances are in train and test?\n",
    "* Provide a frequency distribution of the NERC labels, i.e., how many times does each NERC label occur?\n",
    "* Discuss to what extent the training and test data is balanced (equal amount of instances for each NERC label) and to what extent the training and test data differ?\n",
    "\n",
    "Tip: you can use the following `Counter` functionality to generate frequency list of a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2, 2: 2, 3: 1, 5: 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter \n",
    "\n",
    "my_list=[1,2,1,3,2,5]\n",
    "Counter(my_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in training data: 203621\n",
      "Number of instances in test data: 46435\n"
     ]
    }
   ],
   "source": [
    "# determines the number of instances in the train and test data and print those numbers\n",
    "num_train_instances = len(training_features)\n",
    "num_test_instances = len(test_features)\n",
    "\n",
    "print(f\"Number of instances in training data: {num_train_instances}\")\n",
    "print(f\"Number of instances in test data: {num_test_instances}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - NERC Label Frequency\n",
      "    Label  Frequency\n",
      "1       O     169578\n",
      "5   B-LOC       7140\n",
      "3   B-PER       6600\n",
      "0   B-ORG       6321\n",
      "4   I-PER       4528\n",
      "6   I-ORG       3704\n",
      "2  B-MISC       3438\n",
      "8   I-LOC       1157\n",
      "7  I-MISC       1155\n",
      "---\n",
      "Test Data - NERC Label Frequency\n",
      "    Label  Frequency\n",
      "0       O      38323\n",
      "1   B-LOC       1668\n",
      "7   B-ORG       1661\n",
      "2   B-PER       1617\n",
      "3   I-PER       1156\n",
      "8   I-ORG        835\n",
      "5  B-MISC        702\n",
      "4   I-LOC        257\n",
      "6  I-MISC        216\n"
     ]
    }
   ],
   "source": [
    "# compute the frequency of each label and create a dataframe for nicer visualization\n",
    "train_label_distribution = Counter(training_gold_labels)\n",
    "test_label_distribution = Counter(test_gold_labels)\n",
    "train_label_df = pd.DataFrame(train_label_distribution.items(), columns=['Label', 'Frequency']).sort_values(by='Frequency', ascending=False)\n",
    "test_label_df = pd.DataFrame(test_label_distribution.items(), columns=['Label', 'Frequency']).sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "print(\"Training Data - NERC Label Frequency\")\n",
    "print(train_label_df)\n",
    "print(\"---\")\n",
    "print(\"Test Data - NERC Label Frequency\")\n",
    "print(test_label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - Label Distribution (%)\n",
      "    Label  Percentage\n",
      "1       O       83.28\n",
      "5   B-LOC        3.51\n",
      "3   B-PER        3.24\n",
      "0   B-ORG        3.10\n",
      "4   I-PER        2.22\n",
      "6   I-ORG        1.82\n",
      "2  B-MISC        1.69\n",
      "7  I-MISC        0.57\n",
      "8   I-LOC        0.57\n",
      "---\n",
      "Test Data - Label Distribution (%)\n",
      "    Label  Percentage\n",
      "0       O       82.53\n",
      "1   B-LOC        3.59\n",
      "7   B-ORG        3.58\n",
      "2   B-PER        3.48\n",
      "3   I-PER        2.49\n",
      "8   I-ORG        1.80\n",
      "5  B-MISC        1.51\n",
      "4   I-LOC        0.55\n",
      "6  I-MISC        0.47\n"
     ]
    }
   ],
   "source": [
    "# get the total number of labels\n",
    "train_total_labels = sum(train_label_distribution.values())\n",
    "test_total_labels = sum(test_label_distribution.values())\n",
    "\n",
    "# compute the percentage of each label and create a dataframe for nicer visualization\n",
    "train_balance = {label: round((count / train_total_labels) * 100, 2) for label, count in train_label_distribution.items()}\n",
    "test_balance = {label: round((count / test_total_labels) * 100, 2) for label, count in test_label_distribution.items()}\n",
    "train_balance_df = pd.DataFrame(train_balance.items(), columns=['Label', 'Percentage']).sort_values(by='Percentage', ascending=False)\n",
    "test_balance_df = pd.DataFrame(test_balance.items(), columns=['Label', 'Percentage']).sort_values(by='Percentage', ascending=False)\n",
    "\n",
    "# print the label distributions for the train and test data\n",
    "print(\"Training Data - Label Distribution (%)\")\n",
    "print(train_balance_df)\n",
    "print(\"---\")\n",
    "print(\"Test Data - Label Distribution (%)\")\n",
    "print(test_balance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *To what extent is the training and test data balanced (equal amount of instances for each NERC label)?*\n",
    "\n",
    "Both the training and test datasets are **highly imbalanced**. In both sets, the \"O\" label dominates, representing over 80% of the data (83.28% in training and 82.53% in test). The remaining NERC labels are present in much smaller proportions (ranging roughly between 0.47% and 3.59%), indicating that there is a significant disparity in the number of instances per label.\n",
    "\n",
    "\n",
    "##### *To what extent do the training and test data differ?*\n",
    "\n",
    "Although the absolute number of instances differs significantly (203621 in training vs. 46435 in test), the **relative distribution of NERC labels is very similar** between the two datasets. The percentages for each label in the training data closely mirror those in the test data, suggesting that the test set is representative of the training set in terms of label distribution, despite minor variations in percentages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2 points] c) Concatenate the train and test features (the list of dictionaries) into one list. Load it using the *DictVectorizer*. Afterwards, split it back to training and test.**\n",
    "\n",
    "Tip: You’ve concatenated train and test into one list and then you’ve applied the DictVectorizer.\n",
    "The order of the rows is maintained. You can hence use an index (number of training instances) to split the_array back into train and test. Do NOT use: `\n",
    "from sklearn.model_selection import train_test_split` here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features array: (203621, 27361)\n",
      "Shape of test features array: (46435, 27361)\n"
     ]
    }
   ],
   "source": [
    "# concatenate the features lists and transform them using DictVectorizer\n",
    "vec = DictVectorizer()\n",
    "all_features = training_features + test_features \n",
    "the_array = vec.fit_transform(all_features)  # Joana: adding .toarray() makes my kernel crash, without it seems to work fine tho\n",
    "\n",
    "# split the features into train and test lists again\n",
    "train_features_array = the_array[:num_train_instances]\n",
    "test_features_array = the_array[num_train_instances:]\n",
    "\n",
    "# check whether split has been done correctly\n",
    "print(\"Shape of training features array:\", train_features_array.shape)\n",
    "print(\"Shape of test features array:\", test_features_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4 points] d) Train the SVM using the train features and labels and evaluate on the test data. Provide a classification report (sklearn.metrics.classification_report).**\n",
    "The train (*lin_clf.fit*) might take a while. On my computer, it took 1min 53s, which is acceptable. Training models normally takes much longer. If it takes more than 5 minutes, you can use a subset for training. Describe the results:\n",
    "* Which NERC labels does the classifier perform well on? Why do you think this is the case?\n",
    "* Which NERC labels does the classifier perform poorly on? Why do you think this is the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the SVM classifier\n",
    "lin_clf = svm.LinearSVC(max_iter=10000) # max_iter added to remove the problems related to convergence, 5k didnt work.\n",
    "# To remove the convergence error we need to increase the maximum number of iterations, but the time goes up with it.\n",
    "\n",
    "# Joana: I don't get a convergence error with 10k iterations\n",
    "# Mahbod: yh, if you use 1k or 5k you will get an error, so let's just stick to 10k, cuz I manually added the max_iter param, it was never there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearSVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(max_iter=10000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(max_iter=10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the training data\n",
    "lin_clf.fit(train_features_array, training_gold_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.81      0.78      0.79      1668\n",
      "      B-MISC       0.78      0.66      0.72       702\n",
      "       B-ORG       0.79      0.52      0.63      1661\n",
      "       B-PER       0.86      0.44      0.58      1617\n",
      "       I-LOC       0.62      0.53      0.57       257\n",
      "      I-MISC       0.57      0.59      0.58       216\n",
      "       I-ORG       0.70      0.47      0.56       835\n",
      "       I-PER       0.33      0.87      0.48      1156\n",
      "           O       0.98      0.98      0.98     38323\n",
      "\n",
      "    accuracy                           0.92     46435\n",
      "   macro avg       0.72      0.65      0.65     46435\n",
      "weighted avg       0.94      0.92      0.92     46435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test data\n",
    "test_predictions = lin_clf.predict(test_features_array)\n",
    "report = classification_report(test_gold_labels, test_predictions)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Labels the Classifier Performs Well On & Reason Why*\n",
    "\n",
    "\n",
    "- **Label \"O\":** \n",
    " The classifier achieves exceptional performance on the \"O\" label, with a precision and recall of 0.98 (f1-score = 0.98). This is likely because \"O\" constitutes the vast majority of tokens in the dataset, providing abundant training examples and making non-entity recognition relatively straightforward.\n",
    "\n",
    "- **Label \"B-LOC\":** \n",
    " With a precision of 0.81, recall of 0.78, and an f1-score of 0.79, the classifier performs well on B-LOC. Location entities tend to have distinct contextual features (like accompanying prepositions or specific lexical cues) that make them easier for the model to identify accurately.\n",
    "\n",
    "\n",
    "##### *Labels the Classifier Performs Poorly On & Reason Why*\n",
    "\n",
    "\n",
    "- **Label \"I-PER\":** \n",
    " The classifier performs poorly on I-PER, with a notably low precision of 0.33 despite a high recall of 0.87, resulting in an f1-score of 0.48. This suggests that while the model captures many true I-PER tokens, it also generates a high number of false positives. The difficulty in correctly identifying multi-word person names (deciding when a name starts as B-PER and continues as I-PER) likely causes this issue.\n",
    "\n",
    "- **Label \"B-PER\":** \n",
    " The B-PER label has a low recall of 0.44 despite a high precision of 0.86 (f1-score = 0.58), indicating that the classifier misses a significant number of person entity beginnings. This may be due to challenges in differentiating person names from other similar tokens (such as, perhaps, organization/company names) or insufficient distinctive features in the training examples.\n",
    "\n",
    "- **Other Labels (e.g., I-ORG and I-LOC):** \n",
    " Labels such as I-ORG (f1-score = 0.56), I-LOC (f1-score = 0.57), and I-MISC (f1-score = 0.58) also show relatively lower performance. These difficulties might stem from the challenges of consistently segmenting multi-token entities and overlapping contextual cues between different entity types.\n",
    "\n",
    "\n",
    " ##### SHOULDNT WE BE DESCRIBING FOR EACH ONE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[6 points] e) Train a model that uses the embeddings of these words as inputs. Test again on the same data as in 2d. Generate a classification report and compare the results with the classifier you built in 2d.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "# adapt the path to point to your local copy of the Google embeddings model\n",
    "word_embedding_model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Training Features: [[ 3.73535156e-02 -2.03125000e-01  2.12890625e-01  2.44140625e-01\n",
      "  -2.85156250e-01 -3.44238281e-02  6.68945312e-02 -1.87500000e-01\n",
      "  -3.90625000e-02  8.48388672e-03 -2.89062500e-01 -8.34960938e-02\n",
      "   9.08203125e-02 -2.73437500e-01 -3.92578125e-01 -1.06445312e-01\n",
      "  -6.59179688e-02 -9.94873047e-03 -5.41992188e-02 -4.17480469e-02\n",
      "   2.63671875e-01  7.95898438e-02  1.50390625e-01  1.94335938e-01\n",
      "   2.12890625e-01  9.86328125e-02 -3.35937500e-01  1.58203125e-01\n",
      "   2.83203125e-01  2.33398438e-01 -1.19140625e-01 -2.30468750e-01\n",
      "   2.61718750e-01  5.95703125e-02  2.61230469e-02 -3.41796875e-01\n",
      "  -1.54296875e-01  1.37695312e-01  9.86328125e-02  5.56640625e-02\n",
      "   3.14453125e-01  9.81445312e-02  1.58203125e-01  1.97265625e-01\n",
      "   2.27050781e-02 -7.61718750e-02 -2.96875000e-01  2.18750000e-01\n",
      "  -3.59375000e-01  1.88476562e-01 -1.08398438e-01  3.15856934e-03\n",
      "  -5.83496094e-02  1.96289062e-01  1.28906250e-01 -2.31445312e-01\n",
      "  -3.92578125e-01  1.36108398e-02 -2.94921875e-01 -7.76367188e-02\n",
      "  -1.85546875e-01 -2.98828125e-01  1.40991211e-02  2.17285156e-02\n",
      "   1.29882812e-01 -1.80664062e-01 -1.56250000e-02  1.18164062e-01\n",
      "  -2.67578125e-01 -1.62109375e-01 -1.20605469e-01  2.14843750e-01\n",
      "   1.88476562e-01  1.36718750e-01 -2.98828125e-01 -7.12890625e-02\n",
      "   2.12890625e-01  1.83593750e-01  2.28271484e-02  3.49609375e-01\n",
      "  -3.82812500e-01 -4.16015625e-01  3.14941406e-02  6.98242188e-02\n",
      "   7.91015625e-02  1.93359375e-01 -5.05371094e-02 -3.00781250e-01\n",
      "   1.40625000e-01  2.69531250e-01 -4.80957031e-02 -2.98828125e-01\n",
      "  -2.59765625e-01  1.54296875e-01 -7.66601562e-02 -2.02148438e-01\n",
      "  -5.49316406e-02 -3.57421875e-01  4.21875000e-01 -1.05957031e-01\n",
      "  -5.78613281e-02 -4.02832031e-02 -1.35742188e-01  6.22558594e-02\n",
      "   7.51953125e-02  1.91406250e-01 -1.43554688e-01 -2.00195312e-01\n",
      "   1.55273438e-01 -2.46093750e-01  2.09960938e-01 -1.63085938e-01\n",
      "   1.42578125e-01  3.16406250e-01  2.35351562e-01  1.98242188e-01\n",
      "  -1.35742188e-01  3.61328125e-02  2.98828125e-01  2.07031250e-01\n",
      "   7.76367188e-02 -4.27246094e-02 -2.46093750e-01 -1.71875000e-01\n",
      "   4.51660156e-02 -2.42187500e-01  3.97949219e-02 -1.71661377e-03\n",
      "  -5.39062500e-01 -2.73437500e-02  1.44531250e-01  2.00195312e-01\n",
      "  -1.85546875e-01  5.95703125e-02 -2.11914062e-01 -2.26562500e-01\n",
      "  -5.00488281e-02 -2.23632812e-01  2.85156250e-01 -3.06640625e-01\n",
      "   2.26562500e-01 -4.85839844e-02 -2.05078125e-01  1.02050781e-01\n",
      "  -1.61132812e-02 -1.33789062e-01  2.67578125e-01  1.06933594e-01\n",
      "  -2.91015625e-01 -1.19140625e-01  1.52343750e-01  1.79443359e-02\n",
      "  -4.95605469e-02 -2.08007812e-01  3.55468750e-01 -1.82617188e-01\n",
      "  -9.66796875e-02 -4.02832031e-02  1.16699219e-01  3.83300781e-02\n",
      "  -2.42187500e-01 -1.11816406e-01 -9.58251953e-03 -4.12109375e-01\n",
      "   1.66015625e-01 -1.63085938e-01  1.02539062e-01  6.93359375e-02\n",
      "  -7.95898438e-02  8.10546875e-02 -1.87500000e-01 -1.38671875e-01\n",
      "   8.78906250e-02  8.59375000e-02 -1.20605469e-01 -4.02343750e-01\n",
      "   3.90625000e-02 -2.08984375e-01  1.02050781e-01 -1.07421875e-01\n",
      "   4.61425781e-02  1.69677734e-02  3.47656250e-01 -6.68945312e-02\n",
      "   2.09960938e-01  1.98242188e-01  8.54492188e-02 -8.15429688e-02\n",
      "  -1.47460938e-01 -9.13085938e-02 -1.54296875e-01 -2.61718750e-01\n",
      "  -2.28271484e-02 -8.30078125e-02  3.26171875e-01  3.73046875e-01\n",
      "   3.41796875e-02 -3.90625000e-01 -6.39648438e-02 -3.41796875e-01\n",
      "  -1.19628906e-01 -1.08886719e-01 -5.73730469e-02  2.28515625e-01\n",
      "  -3.20434570e-04  1.31835938e-01  2.73437500e-01 -2.92968750e-01\n",
      "  -5.81054688e-02 -2.18750000e-01 -5.12695312e-02 -1.14257812e-01\n",
      "  -9.66796875e-02  5.00000000e-01 -1.44531250e-01 -3.61328125e-02\n",
      "   2.33459473e-03 -4.61425781e-02  2.50000000e-01 -5.81054688e-02\n",
      "  -3.35937500e-01  2.01416016e-02 -9.61914062e-02  3.08593750e-01\n",
      "  -1.52343750e-01 -1.77734375e-01  3.96484375e-01  2.23632812e-01\n",
      "   4.43359375e-01 -1.26953125e-01 -9.52148438e-02  4.60815430e-03\n",
      "   2.10937500e-01 -1.49414062e-01  2.85644531e-02  1.55273438e-01\n",
      "   5.02929688e-02  1.70898438e-01 -1.84326172e-02 -2.71484375e-01\n",
      "  -1.77001953e-02  1.29882812e-01  1.20605469e-01  5.29785156e-02\n",
      "   2.53906250e-01  3.51562500e-02 -3.12500000e-01 -2.17773438e-01\n",
      "   1.07421875e-02 -1.92382812e-01  2.94189453e-02  4.98046875e-02\n",
      "  -6.64062500e-02  3.80859375e-01  4.33349609e-03 -7.12890625e-02\n",
      "   4.16015625e-01 -1.49414062e-01  3.16406250e-01 -1.05957031e-01\n",
      "  -3.84521484e-03  1.42578125e-01 -5.49316406e-02  1.84570312e-01\n",
      "   2.37304688e-01 -1.44531250e-01 -3.04687500e-01 -3.78906250e-01\n",
      "  -2.85156250e-01 -1.75781250e-01 -2.40478516e-02 -5.59082031e-02\n",
      "   1.66992188e-01  5.27343750e-02 -2.65625000e-01  9.86328125e-02\n",
      "   1.12792969e-01  1.72119141e-02 -1.25000000e-01  1.46484375e-01\n",
      "  -1.19628906e-01  1.95312500e-01 -2.88085938e-02  2.61718750e-01\n",
      "   4.61425781e-02  1.03515625e-01 -1.31835938e-01  3.10546875e-01\n",
      "   9.96093750e-02  2.55859375e-01 -2.99072266e-03  1.63574219e-02\n",
      "  -2.45361328e-02  6.78710938e-02 -1.41601562e-01  4.41406250e-01\n",
      "   8.44726562e-02  1.57226562e-01  2.59765625e-01 -5.88378906e-02]\n",
      " [ 9.82666016e-03  2.26562500e-01  2.81250000e-01 -3.61328125e-01\n",
      "  -6.07910156e-02  5.88378906e-02  1.02050781e-01 -3.54003906e-02\n",
      "   1.47460938e-01  1.28906250e-01 -4.66796875e-01 -1.96533203e-02\n",
      "  -1.11328125e-01  1.08398438e-01 -9.42382812e-02  2.09960938e-01\n",
      "   1.37695312e-01 -3.49121094e-02  1.62109375e-01  4.41894531e-02\n",
      "   5.66406250e-02  1.92382812e-01 -3.26171875e-01  4.37500000e-01\n",
      "   2.00195312e-01 -4.49218750e-01 -3.24218750e-01  1.73828125e-01\n",
      "  -4.34570312e-02  1.88476562e-01  1.56250000e-01 -2.08007812e-01\n",
      "  -6.52343750e-01  2.61718750e-01 -1.73828125e-01 -3.08593750e-01\n",
      "   7.12890625e-02  2.03125000e-01 -2.02148438e-01 -4.21142578e-03\n",
      "   1.58203125e-01 -4.14062500e-01  1.78710938e-01 -2.53906250e-01\n",
      "   4.37011719e-02 -5.50781250e-01 -1.20117188e-01 -6.93359375e-02\n",
      "   2.40234375e-01 -8.34960938e-02 -1.67968750e-01 -1.76757812e-01\n",
      "  -1.87500000e-01 -1.95312500e-01 -3.80859375e-02  5.67626953e-03\n",
      "  -1.42578125e-01 -2.39257812e-01  3.20312500e-01  5.54199219e-02\n",
      "   1.12304688e-01  3.32031250e-01  1.16699219e-01 -1.50390625e-01\n",
      "  -2.21679688e-01 -1.11328125e-01  1.19628906e-01 -1.36718750e-01\n",
      "  -1.63085938e-01  9.66796875e-02  5.62500000e-01 -2.29492188e-01\n",
      "   4.41894531e-02  5.15625000e-01 -3.84765625e-01 -2.49023438e-01\n",
      "   1.25976562e-01  5.97656250e-01  3.88671875e-01  4.08203125e-01\n",
      "   8.10546875e-02 -5.02929688e-02  2.39257812e-01 -7.81250000e-03\n",
      "   2.69531250e-01 -3.94531250e-01 -1.62109375e-01  3.84765625e-01\n",
      "   1.54296875e-01 -2.79296875e-01 -9.27734375e-02 -2.61718750e-01\n",
      "  -8.30078125e-02 -5.63964844e-02  7.78198242e-03  4.96093750e-01\n",
      "  -5.27343750e-02  1.35742188e-01  4.43359375e-01  2.04101562e-01\n",
      "   1.20605469e-01  4.98046875e-02 -7.37304688e-02  3.47656250e-01\n",
      "  -5.54199219e-02 -1.34765625e-01  2.81250000e-01 -1.38671875e-01\n",
      "  -1.45507812e-01 -2.56347656e-02 -5.10253906e-02 -3.24707031e-02\n",
      "  -2.55859375e-01  1.94335938e-01  2.37304688e-01  2.73437500e-01\n",
      "  -3.12500000e-01  2.29492188e-02  1.84570312e-01  1.20605469e-01\n",
      "   1.85546875e-01  2.37304688e-01  7.47070312e-02  7.76367188e-02\n",
      "   1.82617188e-01 -2.89062500e-01 -7.81250000e-03 -7.71484375e-02\n",
      "  -4.61425781e-02 -2.96875000e-01 -9.61914062e-02 -2.35351562e-01\n",
      "   1.36718750e-01 -5.73730469e-02 -3.33984375e-01 -2.51464844e-02\n",
      "  -8.34960938e-02  4.85839844e-02  7.51953125e-02  2.53295898e-03\n",
      "   3.28125000e-01 -3.96484375e-01  2.20703125e-01  1.54296875e-01\n",
      "   8.88671875e-02  1.40991211e-02 -2.81250000e-01  8.97216797e-03\n",
      "   1.39648438e-01  2.83203125e-01  2.91015625e-01 -5.78613281e-02\n",
      "   6.44531250e-02 -2.37304688e-01  1.37695312e-01  1.13525391e-02\n",
      "   1.74804688e-01  1.21582031e-01 -1.32812500e-01 -5.20019531e-02\n",
      "   2.90527344e-02 -3.98437500e-01  2.19726562e-01 -4.10156250e-01\n",
      "   1.55273438e-01  1.17675781e-01  1.45507812e-01 -1.50390625e-01\n",
      "   2.36328125e-01 -6.10351562e-02  2.47192383e-03  5.02929688e-02\n",
      "   8.98437500e-02 -6.98242188e-02  2.12890625e-01  1.83593750e-01\n",
      "   3.17382812e-02  5.44433594e-02 -3.59375000e-01  2.12890625e-01\n",
      "  -2.49023438e-01 -1.13281250e-01 -8.74023438e-02  1.42578125e-01\n",
      "  -1.22558594e-01 -2.08740234e-02 -1.26953125e-01  2.96875000e-01\n",
      "  -6.12792969e-02 -9.91210938e-02  1.60156250e-01  4.17968750e-01\n",
      "  -4.79125977e-03  2.50000000e-01  9.96093750e-02  5.88378906e-02\n",
      "   5.68847656e-02 -1.77734375e-01 -3.22265625e-01  8.00781250e-02\n",
      "   2.57568359e-02 -2.27539062e-01  2.11914062e-01 -8.44726562e-02\n",
      "  -2.91015625e-01  3.49609375e-01  1.30859375e-01  1.40625000e-01\n",
      "   1.08642578e-02 -2.83203125e-01  9.66796875e-02  1.59179688e-01\n",
      "  -3.24707031e-02 -3.39355469e-02 -2.81250000e-01 -1.04980469e-01\n",
      "  -1.50390625e-01 -5.39550781e-02  1.08886719e-01 -4.12597656e-02\n",
      "   2.62451172e-03 -1.71875000e-01 -9.61914062e-02  4.19921875e-01\n",
      "   6.22558594e-02 -1.23535156e-01  1.85546875e-01 -6.64062500e-02\n",
      "   1.23046875e-01  2.87109375e-01  5.95703125e-02 -5.46875000e-02\n",
      "   8.34960938e-02  2.20703125e-01  1.37695312e-01 -1.50390625e-01\n",
      "   2.61718750e-01 -1.62109375e-01  4.43359375e-01  1.62109375e-01\n",
      "   2.34375000e-01  1.79443359e-02  5.68847656e-02  3.22265625e-01\n",
      "   7.17773438e-02  9.76562500e-02 -3.39843750e-01  2.29492188e-01\n",
      "   1.55273438e-01 -1.42578125e-01  9.22851562e-02  1.77734375e-01\n",
      "  -1.17675781e-01  7.56835938e-02  7.42187500e-02  1.37695312e-01\n",
      "   1.70898438e-01  5.02929688e-02  4.00390625e-01  2.59765625e-01\n",
      "  -1.66015625e-01  4.76074219e-02  5.29785156e-02 -6.83593750e-02\n",
      "   3.10546875e-01  3.96484375e-01 -4.06250000e-01 -1.33789062e-01\n",
      "  -1.35742188e-01 -9.03320312e-02 -3.02734375e-01  1.25976562e-01\n",
      "   3.59375000e-01 -2.92968750e-01  1.24023438e-01 -2.43164062e-01\n",
      "  -2.08007812e-01 -1.97265625e-01 -2.64892578e-02  1.33789062e-01\n",
      "  -1.62109375e-01  6.10351562e-02 -3.57421875e-01  2.03125000e-01\n",
      "   3.59375000e-01 -1.52587891e-02  1.04980469e-01  1.41601562e-01\n",
      "   2.30468750e-01 -2.71484375e-01 -7.51953125e-02 -1.85546875e-01\n",
      "  -2.83203125e-01  3.18359375e-01 -3.61328125e-01  2.51953125e-01\n",
      "   7.86132812e-02  3.06396484e-02 -1.03515625e-01  2.03125000e-01]]\n",
      "Sample Training Labels: ['B-ORG' 'O']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Training Data\n",
    "# get the valid tokens and compute how many valid tokens there are\n",
    "valid_tokens = [(token, ne_label) for token, pos, ne_label in train.iob_words() if token and token != 'DOCSTART']\n",
    "num_tokens = len(valid_tokens)\n",
    "\n",
    "# based on the number of tokens make arrays to store the word embedding features and their labels\n",
    "train_word_embeddings = np.zeros((num_tokens, 300))\n",
    "train_word_embeddings_labels = np.empty(num_tokens, dtype=object)\n",
    "\n",
    "# go through the valid tokens\n",
    "for i, (token, ne_label) in enumerate(valid_tokens):\n",
    "    # if the token exist in Google's embedding model, use the word embedding\n",
    "    if token in word_embedding_model:\n",
    "        train_word_embeddings[i] = word_embedding_model[token]\n",
    "\n",
    "    # add the label to the label array\n",
    "    train_word_embeddings_labels[i] = ne_label\n",
    "\n",
    "# check\n",
    "print(\"Sample Training Features:\", train_word_embeddings[:2])\n",
    "print(\"Sample Training Labels:\", train_word_embeddings_labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Training Features: [[ 1.26953125e-01  2.60009766e-02  2.69531250e-01 -1.32812500e-01\n",
      "   5.05371094e-02  8.11767578e-03 -1.33789062e-01 -2.91015625e-01\n",
      "  -2.53906250e-01  2.81250000e-01 -9.91210938e-02 -5.22460938e-02\n",
      "  -4.88281250e-01  1.12792969e-01 -2.66113281e-02  2.81250000e-01\n",
      "   2.67578125e-01  3.37890625e-01 -1.77734375e-01  5.76171875e-02\n",
      "  -1.06445312e-01  3.06640625e-01  3.33984375e-01 -1.85546875e-01\n",
      "  -1.47705078e-02  6.15234375e-02  2.65625000e-01  3.04687500e-01\n",
      "   2.41210938e-01  3.02734375e-01  4.46777344e-02  5.73730469e-02\n",
      "  -1.57226562e-01 -6.64062500e-01 -1.26953125e-01 -1.42578125e-01\n",
      "  -5.71289062e-02  1.92260742e-03 -1.06933594e-01  1.81884766e-02\n",
      "  -3.24218750e-01 -6.99218750e-01  1.32812500e-01  6.86645508e-05\n",
      "   1.62109375e-01 -3.75000000e-01  2.59765625e-01  5.22460938e-02\n",
      "   1.68457031e-02  3.98437500e-01 -2.08984375e-01  3.53515625e-01\n",
      "  -4.54101562e-02  1.57226562e-01 -6.05468750e-02 -1.96289062e-01\n",
      "  -1.05468750e-01 -1.05957031e-01 -2.06298828e-02  4.27246094e-03\n",
      "  -4.23828125e-01 -2.57812500e-01 -1.06933594e-01  4.12109375e-01\n",
      "  -2.49023438e-01 -3.33984375e-01  2.42187500e-01 -2.30468750e-01\n",
      "   3.08593750e-01  1.44531250e-01  2.35351562e-01 -8.00781250e-02\n",
      "   3.12500000e-02 -1.81640625e-01  7.12890625e-02  1.93359375e-01\n",
      "   1.74804688e-01  1.29882812e-01  1.43554688e-01 -9.76562500e-02\n",
      "  -1.84570312e-01  4.19921875e-02 -1.60156250e-01 -5.81054688e-02\n",
      "  -2.90527344e-02 -2.38281250e-01 -3.45703125e-01  1.86523438e-01\n",
      "   7.08007812e-03 -3.08593750e-01 -1.65039062e-01 -8.05664062e-02\n",
      "   4.25781250e-01 -7.56835938e-02  8.30078125e-02  1.36718750e-01\n",
      "  -1.06445312e-01 -3.29589844e-02  4.27734375e-01  2.12890625e-01\n",
      "   3.24707031e-02  4.12109375e-01  5.50781250e-01 -6.59179688e-02\n",
      "   2.00195312e-01  3.16406250e-01  2.46093750e-01 -2.19726562e-01\n",
      "  -1.30859375e-01 -1.64794922e-02  3.98437500e-01 -1.62109375e-01\n",
      "  -1.64062500e-01 -3.37890625e-01  8.25195312e-02  4.88281250e-01\n",
      "  -2.55859375e-01  1.59179688e-01  1.06445312e-01 -2.71484375e-01\n",
      "  -2.22656250e-01 -1.08398438e-01  1.42578125e-01 -1.51367188e-01\n",
      "  -2.15820312e-01  1.17187500e-01 -6.05468750e-01  2.19726562e-01\n",
      "  -4.83398438e-02 -5.37109375e-02  2.61718750e-01 -5.07812500e-01\n",
      "   2.47070312e-01 -6.40625000e-01 -1.11083984e-02  8.39843750e-02\n",
      "  -2.02148438e-01  1.85546875e-01  1.97753906e-02  3.02734375e-01\n",
      "   1.56250000e-01 -1.40625000e-01  2.65625000e-01 -7.95898438e-02\n",
      "   1.20605469e-01  1.26953125e-01 -9.13085938e-02  3.78906250e-01\n",
      "   3.26171875e-01 -2.36328125e-01  3.12500000e-01 -2.69775391e-02\n",
      "  -1.47460938e-01 -2.55859375e-01 -4.27734375e-01  1.65039062e-01\n",
      "   1.92871094e-02 -2.39257812e-02 -7.17773438e-02 -4.17968750e-01\n",
      "   4.66308594e-02  1.47460938e-01  3.10546875e-01 -4.66796875e-01\n",
      "   1.01562500e-01 -2.10571289e-03  1.48437500e-01 -1.76757812e-01\n",
      "  -3.49609375e-01  1.73339844e-02  2.53906250e-01  2.23632812e-01\n",
      "  -6.01562500e-01 -1.72851562e-01  9.08203125e-02  3.24707031e-02\n",
      "   8.10546875e-02  1.03027344e-01 -3.06396484e-02 -1.66992188e-01\n",
      "  -1.37695312e-01  1.81640625e-01  4.76562500e-01 -3.58886719e-02\n",
      "  -2.03125000e-01  2.55859375e-01  1.60156250e-01 -2.89062500e-01\n",
      "   1.14257812e-01  3.61328125e-02 -8.15429688e-02 -3.69140625e-01\n",
      "  -2.77343750e-01 -2.27539062e-01 -2.06054688e-01 -1.15234375e-01\n",
      "   2.77343750e-01  2.61718750e-01 -3.12500000e-01 -3.39355469e-02\n",
      "  -1.85546875e-01 -2.89062500e-01  1.57226562e-01 -8.72802734e-03\n",
      "  -2.43164062e-01 -3.71093750e-01  1.59179688e-01 -1.48925781e-02\n",
      "  -5.66406250e-02 -1.76757812e-01  4.32128906e-02  4.02343750e-01\n",
      "   2.75390625e-01  2.65625000e-01 -7.81250000e-02 -1.15966797e-02\n",
      "   1.17675781e-01 -2.57812500e-01 -2.89062500e-01  2.18505859e-02\n",
      "  -1.68945312e-01 -1.51367188e-01  6.07910156e-02  1.42578125e-01\n",
      "  -1.14135742e-02  1.65039062e-01  4.49218750e-02 -1.84326172e-02\n",
      "   1.25000000e-01 -3.28125000e-01  3.26171875e-01  3.30078125e-01\n",
      "  -2.81250000e-01  6.00585938e-02  1.32812500e-01  7.95898438e-02\n",
      "   1.00097656e-01 -1.10351562e-01 -1.64062500e-01 -3.08593750e-01\n",
      "  -6.49414062e-02 -1.24023438e-01  1.85546875e-01  4.30297852e-03\n",
      "  -1.46484375e-01 -4.41894531e-02 -5.00000000e-01  3.12500000e-01\n",
      "  -4.10156250e-01  3.06640625e-01  2.98828125e-01  2.30468750e-01\n",
      "   4.58984375e-01  3.30078125e-01  9.66796875e-02  1.21582031e-01\n",
      "   3.55468750e-01 -1.60156250e-01 -2.33398438e-01  2.42187500e-01\n",
      "  -5.27343750e-02 -3.32031250e-02  3.10546875e-01 -8.34960938e-02\n",
      "  -9.22851562e-02  2.73437500e-01 -5.66406250e-01  4.23828125e-01\n",
      "  -1.54418945e-02  1.25732422e-02 -2.87109375e-01  3.20312500e-01\n",
      "  -1.37695312e-01 -1.26953125e-01 -3.73535156e-02  1.30462646e-03\n",
      "   6.44531250e-02 -1.56250000e-02  3.68652344e-02  1.48437500e-01\n",
      "  -1.07421875e-01  2.32421875e-01 -2.36328125e-01 -2.40234375e-01\n",
      "   3.18359375e-01 -5.68847656e-02  2.02148438e-01 -3.88183594e-02\n",
      "   2.98828125e-01 -1.51367188e-01  5.68847656e-02 -2.47070312e-01\n",
      "   3.47900391e-03 -6.29882812e-02 -7.56835938e-02  9.96093750e-02\n",
      "   1.25000000e-01  5.71289062e-02  5.54199219e-02  4.33593750e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "Sample Training Labels: ['O' 'O']\n"
     ]
    }
   ],
   "source": [
    "# Test Data\n",
    "# get the valid tokens and compute how many valid tokens there are\n",
    "valid_tokens = [(token, ne_label) for token, pos, ne_label in test.iob_words() if token and token != 'DOCSTART']\n",
    "num_tokens = len(valid_tokens)\n",
    "\n",
    "# based on the number of tokens make arrays to store the word embedding features and their labels\n",
    "test_word_embeddings = np.zeros((num_tokens, 300))\n",
    "test_word_embeddings_labels = np.empty(num_tokens, dtype=object)\n",
    "\n",
    "# go through the valid tokens\n",
    "for i, (token, ne_label) in enumerate(valid_tokens):\n",
    "    # if the token exist in Google's embedding model, use the word embedding\n",
    "    if token in word_embedding_model:\n",
    "        test_word_embeddings[i] = word_embedding_model[token]\n",
    "\n",
    "    # add the label to the label array\n",
    "    test_word_embeddings_labels[i] = ne_label\n",
    "\n",
    "# check\n",
    "print(\"Sample Training Features:\", test_word_embeddings[:2])\n",
    "print(\"Sample Training Labels:\", test_word_embeddings_labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features array: (203621, 300)\n",
      "Shape of test features array: (46435, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training features array:\", train_word_embeddings.shape)\n",
    "print(\"Shape of test features array:\", test_word_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the SVM classifier\n",
    "lin_clf_we = svm.LinearSVC(max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearSVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(max_iter=10000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(max_iter=10000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the training data\n",
    "lin_clf_we.fit(train_word_embeddings, train_word_embeddings_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.76      0.80      0.78      1668\n",
      "      B-MISC       0.72      0.70      0.71       702\n",
      "       B-ORG       0.69      0.64      0.66      1661\n",
      "       B-PER       0.75      0.67      0.71      1617\n",
      "       I-LOC       0.51      0.42      0.46       257\n",
      "      I-MISC       0.60      0.54      0.57       216\n",
      "       I-ORG       0.48      0.33      0.39       835\n",
      "       I-PER       0.59      0.50      0.54      1156\n",
      "           O       0.97      0.99      0.98     38323\n",
      "\n",
      "    accuracy                           0.93     46435\n",
      "   macro avg       0.68      0.62      0.64     46435\n",
      "weighted avg       0.92      0.93      0.92     46435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test data\n",
    "test_predictions_we = lin_clf_we.predict(test_word_embeddings)\n",
    "report_we = classification_report(test_word_embeddings_labels, test_predictions_we)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report_we)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Comparison of Results With and Without Word Embeddings*\n",
    "\n",
    "* Starting with overall perfermance results the accuracy was very similar - without word embeddings (1d), it is 0.92, while with word embeddings (1e) it improves to 0.93. The f1-score is slightly higher in the case of not using word embeddings (0.65 compared to 0.64). Therefore, SVM without word embeddings handles minority classes such as I-ORG, I-LOC, I-MISC, B-MISC, and B-LOC slighly better.\n",
    "\n",
    "* Looking at the results per category, we can observe significant increase when using word embeddings in certain categories. First, B-ORG f1-score increases from 0.63 to 0.66. This means that word embeddings can help to recognize and classify organization names better. Also, B-PER and I-PER results are improved with f1-score (0.58 --> 0.71) and (0.48 --> 0.54), meaning that embeddings are also useful for person name recognition. \n",
    "\n",
    "    Reasons that could explain the improvements in these categories:\n",
    "    * semantic representation (meaning and relationships between words); \n",
    "    * ability to handle variations in entity names (generalize across different forms of the same entity);\n",
    "    * contextual understanding of named entities (when certain word sequences belong to specific entity types);\n",
    "    * the traditional SVM without word embeddings relies on handcrafted features that do not recognize deeper connections and relationships between words.\n",
    "\n",
    "* However, for other categories such as I-LOC, I-ORG, the embeddings lowered the scores. The f1-score of I-LOC is significantly lower when using word embeddings (0.57 to 0.46), meaning that model in 1e has even more difficulties recognizing multi-word location entities. Similarly, for I-ORG, the f1-score descreases from 0.56 to 0.39. Embeddings fail to take into account the contextual dependencies of inside-organization entities. \n",
    "\n",
    "    Reasons that could explain the deteriotation in these categories:\n",
    "    * The SVM with word embeddings does not use some details employed by the traditional SVM (e.g. capitalization). It also does not have Pthe OS tags as features, which the traditional SVM utilizes. These minor differences may have caused the worse performance in inside-entity recognition;\n",
    "    * Inside entity labels heavily depend on previous classification. If the model fails to classify labels such as B-LOC and B-ORG, there will also be mistakes on the inside part;\n",
    "    * Word embeddings can cause ambiguity by incorrectly grouping similar words together based on their context. The same word can have different meanings and word embeddings treat identical words the same, regardless of the specific context.\n",
    "\n",
    "* It is also important to note that the O label remains nearly identical in both models (without word embeddings, the precision, recall and f1-score are 0.98, while, with word embeddings, the results are 0.97 (precision), 0.99 (recall), 0.98 (f1-score)). Both models perform equally well in classifying non-entity words. This can be explained by the fact that the O label was the majority of the dataset (see exercise 1b). Both models can perform well on this category because there are many examples of these words, making it easier to do the classfication. Moreover, O label words are less complex (no complex context, semantics), and they are generalizable. \n",
    "\n",
    "In conclusion, the word embeddings model in 1e performs better for recognizing organizations and person names but is less efficient with classifying inside entity labels for locations and organizations compared to the traditional SVM. The choice between these two depends on the what priorities of the features are decided and the goals of the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Points: 10] Exercise 2 (NERC): feature inspection using the [Annotated Corpus for Named Entity Recognition](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus)\n",
    "**[6 points] a. Perform the same steps as in the previous exercise. Make sure you end up for both the training part (*df_train*) and the test part (*df_test*) with:**\n",
    "* the features representation using **DictVectorizer**\n",
    "* the NERC labels in a list\n",
    "\n",
    "Please note that this is the same setup as in the previous exercise:\n",
    "* load both train and test using:\n",
    "    * list of dictionaries for features\n",
    "    * list of NERC labels\n",
    "* combine train and test features in a list and represent them using one hot encoding\n",
    "* train using the training features and NERC labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ld/b7r007xx5qz0wj4jq0413dtm0000gn/T/ipykernel_26378/3303255066.py:3: ParserWarning: Skipping line 281837: expected 25 fields, saw 34\n",
      "\n",
      "  kaggle_dataset = pandas.read_csv(path, on_bad_lines=\"warn\", encoding = 'latin1')\n"
     ]
    }
   ],
   "source": [
    "##### Adapt the path to point to your local copy of NERC_datasets\n",
    "path = './ner_v2.csv'\n",
    "kaggle_dataset = pandas.read_csv(path, on_bad_lines=\"warn\", encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050795"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kaggle_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 20000\n"
     ]
    }
   ],
   "source": [
    "# given code\n",
    "df_train = kaggle_dataset[:100000]\n",
    "df_test = kaggle_dataset[100000:120000]\n",
    "\n",
    "print(len(df_train), len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When we include all of the columns of the dataset as features, this causes the vectors to become very sparse, resulting in the classifier being able to only properly predict the `0` class. To avoid this, we have selected a subset of the columns as features of the model, which significantly increased performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'word', 'lemma','shape', 'pos',\n",
    "    'prev-word','prev-pos', 'prev-shape', 'prev-iob', 'prev-prev-iob'\n",
    "    'next-word','next-pos', 'next-shape',\n",
    "    'next-next-word', 'next-next-pos','next-next-shape'\n",
    "    'sentence_id'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Features Breakdown & Justification*  \n",
    "\n",
    "* **`word`** – The current token; core input for entity recognition.\n",
    "\n",
    "* **`lemma`** – Base form of the word; reduces sparsity by normalizing word variations. Adding the lemmatized versions of `prev-prev-word`, `prev-word`, `next-word`, and `next-next-word`did not improve the performance and were therefore not included in the final selection.\n",
    "\n",
    "* **`shape`** – Captures capitalization patterns of the word; helps detect named entities, which have distinct capitalization.\n",
    "\n",
    "* **`pos`** – Part-of-Speech tag; used for distinguishing between entity types (e.g., proper nouns for names).  \n",
    "\n",
    "* **`prev-word`**, **`next-word`**, **`next-next-word`** - The word before, one and two positions after current word. Help capture named entities consisting of multiple words (e.g., _**New** York City_, _New **York** City_, _New York **City**_).\n",
    "\n",
    "* **`prev-pos`**, **`next-pos`**, **`next-next-pos`** - POS tags of the word before, one and two positions after the current word. Helps provide context by looking at the surroundings of the current word, as the POS tags of words in a multi-word named entity are often dependent on each other.\n",
    "\n",
    "* **`prev-shape`**, **`next-shape`**, **`next-next-shape`** – Captures capitalization patterns for names/organizations consisting of more than one word.\n",
    "\n",
    "* **`prev-iob`** – IOB (Inside-Outside-Beginning) tag of the previous word; helps determine if a word continues an entity (`B-` or `I-`labels).  \n",
    "\n",
    "* **`prev-prev-iob`** – In case of longer named entities, this captures the IOB tag of the word two positions before. Excluding this feature noticably impairs model performance.\n",
    "\n",
    "* **`sentence_id`** – Identifies which sentence the word belongs to; ensures entity predictions don’t span across sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Training Feature: {'lemma': 'london', 'next-next-pos': 'VB', 'next-next-word': 'protest', 'next-pos': 'TO', 'next-shape': 'lowercase', 'pos': 'NNP', 'prev-iob': 'O', 'prev-pos': 'IN', 'prev-shape': 'lowercase', 'prev-word': 'through', 'shape': 'capitalized', 'word': 'London'}\n",
      "Sample Training Label: B-geo\n"
     ]
    }
   ],
   "source": [
    "ner_training_features = []\n",
    "ner_training_gold_labels = []\n",
    "\n",
    "for index, instance in df_train.iterrows():\n",
    "    features_dict = {}\n",
    "    for key, value in instance.items():\n",
    "        if key in selected_features:\n",
    "            features_dict[key] = value\n",
    "        elif key == \"tag\": \n",
    "            ne_label = value\n",
    "\n",
    "    # append the features and NE label of the instance\n",
    "    ner_training_features.append(features_dict)\n",
    "    ner_training_gold_labels.append(ne_label)\n",
    "\n",
    "# Check\n",
    "print(\"Sample Training Feature:\", ner_training_features[6])\n",
    "print(\"Sample Training Label:\", ner_training_gold_labels[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Test Feature: {'lemma': 'america', 'next-next-pos': 'VBD', 'next-next-word': 'marched', 'next-pos': '``', 'next-shape': 'punct', 'pos': 'NNP', 'prev-iob': 'O', 'prev-pos': 'TO', 'prev-shape': 'lowercase', 'prev-word': 'to', 'shape': 'capitalized', 'word': 'America'}\n",
      "Sample Test Label: B-geo\n"
     ]
    }
   ],
   "source": [
    "ner_test_features = []\n",
    "ner_test_gold_labels = []\n",
    "\n",
    "for index, instance in df_test.iterrows():\n",
    "    features_dict = {}\n",
    "    for key, value in instance.items():\n",
    "        if key in selected_features:\n",
    "            features_dict[key] = value\n",
    "        elif key == \"tag\":  \n",
    "            ne_label = value\n",
    "    \n",
    "    # append the features and NE label of the instance\n",
    "    ner_test_features.append(features_dict)\n",
    "    ner_test_gold_labels.append(ne_label)\n",
    "\n",
    "# Check\n",
    "print(\"Sample Test Feature:\", ner_test_features[3])\n",
    "print(\"Sample Test Label:\", ner_test_gold_labels[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in training data: 100000\n",
      "Number of instances in test data: 20000\n"
     ]
    }
   ],
   "source": [
    "# checks the number of instances in the train and test data and print those numbers\n",
    "num_ner_train_instances = len(ner_training_features)\n",
    "num_ner_test_instances = len(ner_test_features)\n",
    "\n",
    "print(f\"Number of instances in training data: {num_ner_train_instances}\")\n",
    "print(f\"Number of instances in test data: {num_ner_test_instances}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - NERC Label Frequency\n",
      "    Label  Frequency\n",
      "0       O      84725\n",
      "1   B-geo       3303\n",
      "5   B-org       1876\n",
      "10  I-per       1846\n",
      "7   B-tim       1823\n",
      "2   B-gpe       1740\n",
      "3   B-per       1668\n",
      "6   I-org       1470\n",
      "4   I-geo        690\n",
      "12  I-tim        549\n",
      "8   B-art         75\n",
      "14  B-eve         53\n",
      "11  I-gpe         51\n",
      "15  I-eve         47\n",
      "9   I-art         43\n",
      "13  B-nat         30\n",
      "16  I-nat         11\n",
      "---\n",
      "Test Data - NERC Label Frequency\n",
      "    Label  Frequency\n",
      "0       O      16918\n",
      "1   B-geo        741\n",
      "4   B-org        397\n",
      "3   B-tim        393\n",
      "7   B-per        333\n",
      "6   I-org        321\n",
      "8   I-per        319\n",
      "5   B-gpe        296\n",
      "2   I-geo        156\n",
      "9   I-tim        108\n",
      "10  B-nat          8\n",
      "12  I-nat          4\n",
      "13  B-art          4\n",
      "11  I-gpe          2\n"
     ]
    }
   ],
   "source": [
    "# compute the frequency of each label and create a dataframe for nicer visualization\n",
    "ner_train_label_distribution = Counter(ner_training_gold_labels)\n",
    "ner_test_label_distribution = Counter(ner_test_gold_labels)\n",
    "ner_train_label_df = pd.DataFrame(ner_train_label_distribution.items(), columns=['Label', 'Frequency']).sort_values(by='Frequency', ascending=False)\n",
    "ner_test_label_df = pd.DataFrame(ner_test_label_distribution.items(), columns=['Label', 'Frequency']).sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "print(\"Training Data - NERC Label Frequency\")\n",
    "print(ner_train_label_df)\n",
    "print(\"---\")\n",
    "print(\"Test Data - NERC Label Frequency\")\n",
    "print(ner_test_label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - Label Distribution (%)\n",
      "    Label  Percentage\n",
      "0       O       84.72\n",
      "1   B-geo        3.30\n",
      "5   B-org        1.88\n",
      "10  I-per        1.85\n",
      "7   B-tim        1.82\n",
      "2   B-gpe        1.74\n",
      "3   B-per        1.67\n",
      "6   I-org        1.47\n",
      "4   I-geo        0.69\n",
      "12  I-tim        0.55\n",
      "8   B-art        0.07\n",
      "11  I-gpe        0.05\n",
      "14  B-eve        0.05\n",
      "15  I-eve        0.05\n",
      "9   I-art        0.04\n",
      "13  B-nat        0.03\n",
      "16  I-nat        0.01\n",
      "---\n",
      "Test Data - Label Distribution (%)\n",
      "    Label  Percentage\n",
      "0       O       84.59\n",
      "1   B-geo        3.71\n",
      "4   B-org        1.98\n",
      "3   B-tim        1.97\n",
      "7   B-per        1.67\n",
      "6   I-org        1.60\n",
      "8   I-per        1.59\n",
      "5   B-gpe        1.48\n",
      "2   I-geo        0.78\n",
      "9   I-tim        0.54\n",
      "10  B-nat        0.04\n",
      "12  I-nat        0.02\n",
      "13  B-art        0.02\n",
      "11  I-gpe        0.01\n"
     ]
    }
   ],
   "source": [
    "ner_train_total_labels = sum(ner_train_label_distribution.values())\n",
    "ner_test_total_labels = sum(ner_test_label_distribution.values())\n",
    "\n",
    "# compute the percentage of each label and create a dataframe for nicer visualization\n",
    "ner_train_balance = {label: round((count / ner_train_total_labels) * 100, 2) for label, count in ner_train_label_distribution.items()}\n",
    "ner_test_balance = {label: round((count / ner_test_total_labels) * 100, 2) for label, count in ner_test_label_distribution.items()}\n",
    "ner_train_balance_df = pd.DataFrame(ner_train_balance.items(), columns=['Label', 'Percentage']).sort_values(by='Percentage', ascending=False)\n",
    "ner_test_balance_df = pd.DataFrame(ner_test_balance.items(), columns=['Label', 'Percentage']).sort_values(by='Percentage', ascending=False)\n",
    "\n",
    "# print the label distributions for the train and test data\n",
    "print(\"Training Data - Label Distribution (%)\")\n",
    "print(ner_train_balance_df)\n",
    "print(\"---\")\n",
    "print(\"Test Data - Label Distribution (%)\")\n",
    "print(ner_test_balance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features array: (100000, 43272)\n",
      "Shape of test features array: (20000, 43272)\n"
     ]
    }
   ],
   "source": [
    "# concatenate the features lists and transform them to one hot encoding using DictVectorizer\n",
    "vec2 = DictVectorizer()\n",
    "ner_all_features = ner_training_features + ner_test_features \n",
    "ner_array = vec2.fit_transform(ner_all_features)  # Joana: adding .toarray() makes my kernel crash, without it seems to work fine tho\n",
    "\n",
    "# split the features into train and test lists again\n",
    "ner_train_features_array = ner_array[:num_ner_train_instances]\n",
    "ner_test_features_array = ner_array[num_ner_train_instances:]\n",
    "\n",
    "# check whether split has been done correctly\n",
    "print(\"Shape of training features array:\", ner_train_features_array.shape)\n",
    "print(\"Shape of test features array:\", ner_test_features_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4 points] b. Train and evaluate the model and provide the classification report:**\n",
    "* use the SVM to predict NERC labels on the test data\n",
    "* evaluate the performance of the SVM on the test data\n",
    "\n",
    "Analyze the performance per NERC label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the SVM classifier\n",
    "ner_lin_clf = svm.LinearSVC(max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearSVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(max_iter=10000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(max_iter=10000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the training data\n",
    "ner_lin_clf.fit(ner_train_features_array, ner_training_gold_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       1.00      0.50      0.67         4\n",
      "       B-eve       0.00      0.00      0.00         0\n",
      "       B-geo       0.86      0.85      0.85       741\n",
      "       B-gpe       0.90      0.94      0.92       296\n",
      "       B-nat       1.00      0.75      0.86         8\n",
      "       B-org       0.74      0.67      0.71       397\n",
      "       B-per       0.82      0.82      0.82       333\n",
      "       B-tim       0.95      0.84      0.89       393\n",
      "       I-geo       0.97      0.96      0.97       156\n",
      "       I-gpe       1.00      1.00      1.00         2\n",
      "       I-nat       1.00      1.00      1.00         4\n",
      "       I-org       0.95      0.93      0.94       321\n",
      "       I-per       0.94      0.98      0.96       319\n",
      "       I-tim       0.95      0.89      0.92       108\n",
      "           O       0.99      0.99      0.99     16918\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.87      0.81      0.83     20000\n",
      "weighted avg       0.97      0.97      0.97     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test data\n",
    "ner_test_predictions = ner_lin_clf.predict(ner_test_features_array)\n",
    "ner_report = classification_report(ner_test_gold_labels, ner_test_predictions)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(ner_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Analysis of Performance Per Label*\n",
    "\n",
    "- **`B-art`** - Artistic Work \n",
    "  - **Precision: 1.00**: every predicted `B-art` entity was correct  \n",
    "  - **Recall: 0.50**: the model missed half of the actual `B-art` entities  \n",
    "  - **F1-score: 0.67**: moderate performance, but the low recall suggests under-detection   \n",
    "  - The very few examples (**Support: 4**) of this category in the test set make it difficult for the model to be evaluated properly  (there are also not many examples of this category in the training set)\n",
    "\n",
    "- **`B-eve`** - Event  \n",
    "  - **Precision, Recall, F1-score: 0.00**: no instances of this label were present in the test set (**Support: 0**), so the performance of model on this category couldn't be evaluated (there are also few examples of this category in the training set)\n",
    "\n",
    "- **`B-geo`** - Geographical Entity\n",
    "  - **Precision: 0.86**, **Recall: 0.85**, **F1-score: 0.85**: strong and balanced performance across the 3 metrics, meaning the model is relatively accurate in detecting the beginning of location entities\n",
    "  - **Support: 741**: a well-represented category in the test set, contributing to the good performance\n",
    "\n",
    "- **`B-gpe`** - Geopolitical Entity  \n",
    "  - **Precision: 0.90**, **Recall: 0.94**, **F1-score: 0.92**: all metrics are very high, particularly recall, showing that the model is capturing almost all beginnings of geopolitical entities\n",
    "  - **Support: 296** - sufficient testing data is available\n",
    "\n",
    "- **`B-nat`** - Natural Phenomenon\n",
    "  - **Precision: 1.00**, **Recall: 0.75**, **F1-score: 0.86**: perfect precision, meaning the model only labels something as `B-nat` when it is very sure, but lower recall, suggesting it misses some true entities\n",
    "  - **Support: 8**, meaning this is a rare category in the test set, affecting proper evaluation of the model on this category (there are also few examples of this category in the training set)\n",
    "\n",
    "- **`B-org`** - Organization\n",
    "  - **Precision: 0.74**, **Recall: 0.67**, **F1-score: 0.71**: both recall and precision are on the lower side, suggesting the model fails to detect the beginning some organization entities and is prone to more false positive classifications  \n",
    "  - **Support: 397**: even though the category is decently represented, the model struggles here\n",
    "\n",
    "- **`B-per`** - Person  \n",
    "  - **Precision: 0.82**, **Recall: 0.82**, **F1-score: 0.82**: balanced performance, meaning the model both detects and classifies persons well  \n",
    "  - **Support: 333**: well-represented category in the test set, contributing to good results  \n",
    "\n",
    "- **`B-tim`** - Time \n",
    "  - **Precision: 0.95**, **Recall: 0.84**, **F1-score: 0.89**: very high precision indicates the model rarely misclassifies the beginning of time expressions, but slightly lower recall means it can miss some (slightly higher FNs)  \n",
    "  - **Support: 393**: solid performance evaluated on a good amount of test data \n",
    "\n",
    "- **`I-geo`** - Inside a Geographical Entity\n",
    "  - **Precision: 0.97**, **Recall: 0.96**, **F1-score: 0.97**: very high across the 3 metrics, meaning the model correctly classifies multi-word locations\n",
    "  - **Support: 156**: on the lower side in terms of examples in the test set, but still a strong-performing label \n",
    "\n",
    "- **`I-gpe`** - Inside a Geopolitical Entity  \n",
    "  - **Precision, Recall, F1-score: 1.00**: perfect performance, however, since the **Support is only 2** we cannot make a meaningful judgment due to very little test set examples (there are also few examples of this category in the training set)\n",
    "\n",
    "- **`I-nat`** - Inside a Natural Phenomenon\n",
    "  - **Precision, Recall, F1-score: 1.00**: perfect performance, however, since the **Support is only 4** we cannot make a meaningful judgment due to very little test set examples (there are also very few examples of this category in the training set)\n",
    " \n",
    "- **`I-org`** - Inside an Organization\n",
    "  - **Precision: 0.95**, **Recall: 0.93**, **F1-score: 0.94**: very strong performance in recognizing multi-word organizations\n",
    "  - **Support: 321**: well-represented category in the test set, resulting in trustworthy evaluation of the model\n",
    "\n",
    "- **`I-per`** - Inside a Person’s Name \n",
    "  - **Precision: 0.94**, **Recall: 0.98**, **F1-score: 0.96**: high in all metrics, especially recall, suggesting nearly all multi-word names are captured and there are little FPs due to high precision \n",
    "  - **Support: 319**: good representation in the test set leads to proper evaluation of the performance \n",
    "\n",
    "- **`I-tim`** - Inside a Time Expression\n",
    "  - **Precision: 0.95**, **Recall: 0.89**, **F1-score: 0.92**: slightly lower recall but still suggests strong overall performance\n",
    "  - **Support: 108**: on the lower side in terms of examples in the test set but still makes model evaluation for this category possible \n",
    "\n",
    "- **`O`** - Non-Entity Words\n",
    "  - **Precision: 0.99**, **Recall: 0.99**, **F1-score: 0.99**: almost perfect for non-entity words, which is expected  \n",
    "  - **Support: 16918**: by far the largest category in the test set, helping drive the overall accuracy of the model up  \n",
    "\n",
    "- **`Accuracy`**  \n",
    "  - **0.97**: the model correctly predicts `97%` of the tokens in the test set \n",
    "  - Should be interpreted with caution as it can be misleading if the test set is imbalanced (i.e., dominated by the `O` label for non-entity words as is the case here)  \n",
    "\n",
    "- **`Macro Average`** - Average across all entity types, giving equal weight to each class, regardless of frequency\n",
    "  - **Precision: 0.87, Recall: 0.81, F1-score: 0.83**: the recall (`0.81`) is lower than precision (`0.87`), indicating that the model misses some named entities but it still exhibits fairly high overall performance  \n",
    "\n",
    "- **`Weighted Average`** - Similar to `Macro Average` but gives more importance to frequent labels\n",
    "  - **Precision: 0.97, Recall: 0.97, F1-score: 0.97**: since the `O` (non-entities) class dominates, the weighted average is very high, meaning the model performs exceptionally well on the most frequent labels\n",
    "\n",
    "##### *Conclusion*\n",
    "- **Strongest Categories:** `I-org`, `I-per`, `B-gpe`, `I-geo`, and `I-tim`, show very high metrics and reliabile predictions  \n",
    "- **Weakest Categories:** `B-eve` (completely missing), `B-nat`, `B-art`, `I-gpe`, `I-nat` cannot be evaluated properly due to low amount of examples in the test set. Moreover, as the dataset is highly imbalanced, these labels are also underrepresented in the training data, making it hard for the model to learn to classify them correctly.  \n",
    "- The model performs well on common entities like locations, persons, and organizations  \n",
    "- The model handles multi-word entities quite well, as seen with the strong `I-geo`, `I-org`, and `I-per` performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
