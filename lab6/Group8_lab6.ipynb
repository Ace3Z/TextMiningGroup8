{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab6-Assignment: Topic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same training, development, and test partitions of the the 20 newsgroups text dataset as in Lab6.4-Topic-classification-BERT.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fine-tune and examine the performance of another transformer-based pretrained language models, e.g., RoBERTa, XLNet\n",
    "\n",
    "* Compare the performance of this model to the results achieved in Lab6.4-Topic-classification-BERT.ipynb and to a conventional machine learning approach (e.g., SVM, Naive Bayes) using bag-of-words or other engineered features of your choice. \n",
    "Describe the differences in performance in terms of Precision, Recall, and F1-score evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from simpletransformers.classification import ClassificationArgs, ClassificationModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only the four specific categories we need\n",
    "categories = [\"alt.atheism\", \"comp.graphics\", \"sci.med\", \"sci.space\"]\n",
    "\n",
    "# Strip out headers, footers, and quoted text to prevent overfitting\n",
    "train_groups = fetch_20newsgroups(\n",
    "    subset=\"train\",\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "    categories=categories,\n",
    "    random_state=8,\n",
    ")\n",
    "test_groups = fetch_20newsgroups(\n",
    "    subset=\"test\",\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "    categories=categories,\n",
    "    random_state=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({\"text\": train_groups.data, \"labels\": train_groups.target})\n",
    "test_df = pd.DataFrame({\"text\": test_groups.data, \"labels\": test_groups.target})\n",
    "\n",
    "train_df, dev_df = train_test_split(\n",
    "    train_df, test_size=0.1, random_state=0, stratify=train_df[[\"labels\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ClassificationArgs()\n",
    "\n",
    "model_args.overwrite_output_dir = True  \n",
    "\n",
    "# Enable evaluation during training to monitor performance\n",
    "model_args.evaluate_during_training = True  \n",
    "\n",
    "# Training parameters\n",
    "model_args.num_train_epochs = 10  # Train for 10 epochs\n",
    "model_args.train_batch_size = 32  # Process 32 samples per batch\n",
    "model_args.learning_rate = 4e-6  # Learning rate for optimization\n",
    "model_args.max_seq_length = 256  # Max token length per input (the higher the number, the longer it takes)\n",
    "\n",
    "# Early stopping helps prevent overfitting by stopping training \n",
    "# when validation loss stops improving\n",
    "model_args.use_early_stopping = True\n",
    "model_args.early_stopping_delta = 0.01  # Minimum improvement in loss required to continue training\n",
    "model_args.early_stopping_metric = \"eval_loss\"  # The metric to monitor\n",
    "model_args.early_stopping_metric_minimize = True  # Lower eval_loss is better\n",
    "model_args.early_stopping_patience = 2  # Stop training if no improvement in 2 evaluations\n",
    "\n",
    "# Run validation every 32 training steps to track progress\n",
    "model_args.evaluate_during_training_steps = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationArgs(adafactor_beta1=None\n",
      " adafactor_clip_threshold=1.0\n",
      " adafactor_decay_rate=-0.8\n",
      " adafactor_eps=(1e-30\n",
      " 0.001)\n",
      " adafactor_relative_step=True\n",
      " adafactor_scale_parameter=True\n",
      " adafactor_warmup_init=True\n",
      " adam_betas=(0.9\n",
      " 0.999)\n",
      " adam_epsilon=1e-08\n",
      " best_model_dir='outputs/best_model'\n",
      " cache_dir='cache_dir/'\n",
      " config={}\n",
      " cosine_schedule_num_cycles=0.5\n",
      " custom_layer_parameters=[]\n",
      " custom_parameter_groups=[]\n",
      " dataloader_num_workers=0\n",
      " do_lower_case=False\n",
      " dynamic_quantize=False\n",
      " early_stopping_consider_epochs=False\n",
      " early_stopping_delta=0.01\n",
      " early_stopping_metric='eval_loss'\n",
      " early_stopping_metric_minimize=True\n",
      " early_stopping_patience=2\n",
      " encoding=None\n",
      " eval_batch_size=100\n",
      " evaluate_during_training=True\n",
      " evaluate_during_training_silent=True\n",
      " evaluate_during_training_steps=32\n",
      " evaluate_during_training_verbose=False\n",
      " evaluate_each_epoch=True\n",
      " fp16=False\n",
      " gradient_accumulation_steps=1\n",
      " learning_rate=4e-06\n",
      " local_rank=-1\n",
      " logging_steps=50\n",
      " loss_type=None\n",
      " loss_args={}\n",
      " manual_seed=None\n",
      " max_grad_norm=1.0\n",
      " max_seq_length=256\n",
      " model_name='roberta-large'\n",
      " model_type='roberta'\n",
      " multiprocessing_chunksize=-1\n",
      " n_gpu=1\n",
      " no_cache=False\n",
      " no_save=False\n",
      " not_saved_args=[]\n",
      " num_train_epochs=10\n",
      " optimizer='AdamW'\n",
      " output_dir='outputs/'\n",
      " overwrite_output_dir=True\n",
      " polynomial_decay_schedule_lr_end=1e-07\n",
      " polynomial_decay_schedule_power=1.0\n",
      " process_count=6\n",
      " quantized_model=False\n",
      " reprocess_input_data=True\n",
      " save_best_model=True\n",
      " save_eval_checkpoints=True\n",
      " save_model_every_epoch=True\n",
      " save_optimizer_and_scheduler=True\n",
      " save_steps=2000\n",
      " scheduler='linear_schedule_with_warmup'\n",
      " silent=False\n",
      " skip_special_tokens=True\n",
      " tensorboard_dir=None\n",
      " thread_count=None\n",
      " tokenizer_name='roberta-large'\n",
      " tokenizer_type=None\n",
      " train_batch_size=32\n",
      " train_custom_parameters_only=False\n",
      " trust_remote_code=False\n",
      " use_cached_eval_features=False\n",
      " use_early_stopping=True\n",
      " use_hf_datasets=False\n",
      " use_multiprocessing=True\n",
      " use_multiprocessing_for_evaluation=True\n",
      " wandb_kwargs={}\n",
      " wandb_project=None\n",
      " warmup_ratio=0.06\n",
      " warmup_steps=0\n",
      " weight_decay=0.0\n",
      " model_class='ClassificationModel'\n",
      " labels_list=[0\n",
      " 1\n",
      " 2\n",
      " 3]\n",
      " labels_map={}\n",
      " lazy_delimiter='\\t'\n",
      " lazy_labels_column=1\n",
      " lazy_loading=False\n",
      " lazy_loading_start_line=1\n",
      " lazy_text_a_column=None\n",
      " lazy_text_b_column=None\n",
      " lazy_text_column=0\n",
      " onnx=False\n",
      " regression=False\n",
      " sliding_window=False\n",
      " special_tokens_list=[]\n",
      " stride=0.8\n",
      " tie_value=1)\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel(\n",
    "    model_type = \"roberta\",\n",
    "    model_name = \"roberta-large\",\n",
    "    num_labels = 4,\n",
    "    args = model_args,\n",
    "    use_cuda = torch.cuda.is_available(), \n",
    ")\n",
    "\n",
    "print(\"\\n\".join(str(model.args).split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "5it [00:04,  1.01it/s]                       \n",
      "Epoch 1 of 10:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "1it [00:04,  4.28s/it]\n",
      "\n",
      "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "1it [00:04,  4.33s/it]\n",
      "Epochs 1/10. Running Loss:    0.7213: 100%|██████████| 64/64 [55:44<00:00, 52.26s/it]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "1it [00:03,  3.50s/it]\n",
      "Epoch 2 of 10:  10%|█         | 1/10 [58:05<8:42:47, 3485.28s/it]"
     ]
    }
   ],
   "source": [
    "training_results = model.train_model(train_df, eval_df = dev_df) # this fine tuning takes a lot of time, pls run it and lmk if it works\n",
    "\n",
    "history = training_results[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with BoW and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging train and validation sets from above as validation set isn't needed with SVM/NB\n",
    "X_train = pd.concat([train_df[\"text\"], dev_df[\"text\"]])\n",
    "X_test = test_df[\"text\"]\n",
    "y_train = pd.concat([train_df[\"labels\"], dev_df[\"labels\"]])\n",
    "y_test = test_df[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  alt.atheism       0.74      0.70      0.72       319\n",
      "comp.graphics       0.72      0.84      0.78       389\n",
      "      sci.med       0.80      0.69      0.74       396\n",
      "    sci.space       0.71      0.73      0.72       394\n",
      "\n",
      "     accuracy                           0.74      1498\n",
      "    macro avg       0.74      0.74      0.74      1498\n",
      " weighted avg       0.74      0.74      0.74      1498\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# BoW\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Without merging train and validation\n",
    "'''\n",
    "X_train_bow = vectorizer.fit_transform(train_df[\"text\"])\n",
    "X_dev_bow = vectorizer.transform(dev_df[\"text\"])\n",
    "X_test_bow = vectorizer.transform(test_df[\"text\"])\n",
    "\n",
    "y_train, y_dev, y_test = train_df[\"labels\"], dev_df[\"labels\"], test_df[\"labels\"]\n",
    "'''\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "svm_model = svm.LinearSVC()\n",
    "svm_model.fit(X_train_bow, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test_bow)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  alt.atheism       0.84      0.77      0.80       319\n",
      "comp.graphics       0.88      0.88      0.88       389\n",
      "      sci.med       0.88      0.83      0.85       396\n",
      "    sci.space       0.77      0.86      0.82       394\n",
      "\n",
      "     accuracy                           0.84      1498\n",
      "    macro avg       0.84      0.84      0.84      1498\n",
      " weighted avg       0.84      0.84      0.84      1498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "# vectorizer = TfidfVectorizer(min_df=2) -> Slightly better performance\n",
    "\n",
    "X_train_tf = vectorizer.fit_transform(X_train)\n",
    "X_test_tf = vectorizer.transform(X_test)\n",
    "\n",
    "svm_model = svm.LinearSVC()\n",
    "svm_model.fit(X_train_tf, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test_tf)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB with BoW and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  alt.atheism       0.78      0.89      0.83       319\n",
      "comp.graphics       0.91      0.88      0.90       389\n",
      "      sci.med       0.84      0.90      0.87       396\n",
      "    sci.space       0.91      0.77      0.84       394\n",
      "\n",
      "     accuracy                           0.86      1498\n",
      "    macro avg       0.86      0.86      0.86      1498\n",
      " weighted avg       0.87      0.86      0.86      1498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BoW\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train_bow_nb = vectorizer.fit_transform(X_train)\n",
    "X_test_bow_nb = vectorizer.transform(X_test)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_bow_nb, y_train)\n",
    "\n",
    "y_pred = nb_model.predict(X_test_bow_nb)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  alt.atheism       0.88      0.71      0.79       319\n",
      "comp.graphics       0.90      0.87      0.88       389\n",
      "      sci.med       0.76      0.91      0.83       396\n",
      "    sci.space       0.83      0.82      0.83       394\n",
      "\n",
      "     accuracy                           0.83      1498\n",
      "    macro avg       0.84      0.83      0.83      1498\n",
      " weighted avg       0.84      0.83      0.83      1498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "# vectorizer = TfidfVectorizer(min_df=2) -> Slightly better performance\n",
    "\n",
    "X_train_tf_nb = vectorizer.fit_transform(X_train)\n",
    "X_test_tf_nb = vectorizer.transform(X_test)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tf_nb, y_train)\n",
    "\n",
    "y_pred = nb_model.predict(X_test_tf_nb)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=categories))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
